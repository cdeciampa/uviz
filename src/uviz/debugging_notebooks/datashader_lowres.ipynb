{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05349722-1687-48ae-b80d-d886f0de1518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "\n",
    "import geoviews.feature as gf # only needed for coastlines\n",
    "from geoviews.operation import resample_geometry\n",
    "import geoviews as gv\n",
    "from datashader.mpl_ext import dsshow, alpha_colormap\n",
    "\n",
    "#import geocat.datafiles as gdf  # Only for reading-in datasets\n",
    "from xarray import open_mfdataset\n",
    "import xarray as xr\n",
    "\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "\n",
    "from mpas_tools.database.utils import choose_forecast\n",
    "from mpas_tools.plotting.utils import nonlinear_colorbar\n",
    "from mpas_tools.utils.tools import find_TC_bbox\n",
    "from mpas_tools.datashader_tools.utils import datashader_wrapper\n",
    "\n",
    "gv.extension(\"bokeh\",\"matplotlib\")\n",
    "\n",
    "opts.defaults(\n",
    "    opts.Image(width=1200, height=600),\n",
    "    opts.RGB(width=1200, height=600))\n",
    "\n",
    "hv.output(dpi=300, fig='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c0164f-8de1-4c43-9bb1-87d1a59f1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import cartopy.crs as ccrs\n",
    "import xarray as xr\n",
    "import math\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews.operation.datashader import rasterize as hds_rasterize\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "# This funtion splits a global mesh along longitude\n",
    "# Examine the X coordinates of each triangle in 'tris'. \n",
    "# Return an array of 'tris' where only those triangles\n",
    "# with legs whose length is less than 't' are returned.\n",
    "# Makes sure triangle legs are < 90 otherwise they'll cut across the prime meridian\n",
    "\n",
    "def unzipMesh(x,tris,t):\n",
    "    return tris[(np.abs((x[tris[:,0]])-(x[tris[:,1]])) < t) &\\\n",
    "                (np.abs((x[tris[:,0]])-(x[tris[:,2]])) < t)]\n",
    "\n",
    "# Compute the signed area of a triangle - Aidan understands\n",
    "\n",
    "def triArea(x,y,tris):\n",
    "    return ((x[tris[:,1]]-x[tris[:,0]]) *\\\n",
    "            (y[tris[:,2]]-y[tris[:,0]])) - ((x[tris[:,2]]-x[tris[:,0]]) *\\\n",
    "                                            (y[tris[:,1]]-y[tris[:,0]]))\n",
    "\n",
    "# Reorder triangles as necessary so they all have counter clockwise winding order. \n",
    "# CCW is what Datashader and MPL require.\n",
    "\n",
    "def orderCCW(x,y,tris):\n",
    "    tris[triArea(x,y,tris)<0.0,:] = tris[triArea(x,y,tris)<0.0,::-1]\n",
    "    return(tris)\n",
    "\n",
    "# Create a Holoviews Triangle Mesh suitable for rendering with Datashader\n",
    "# This function returns a Holoviews TriMesh that is created from a list of coordinates, \n",
    "# 'x' and 'y', an array of triangle indices that addressess the coordinates in 'x' and 'y', \n",
    "# and a data variable 'var'. The data variable's values will annotate the triangle vertices\n",
    "\n",
    "def createHVTriMesh(x,y,triangle_indices, var, n_workers=1):\n",
    "    # Declare verts array\n",
    "    verts = np.column_stack([x, y, var])\n",
    "\n",
    "    # Convert to pandas\n",
    "    verts_df  = pd.DataFrame(verts,  columns=['x', 'y', 'z'])\n",
    "    tris_df   = pd.DataFrame(triangle_indices, columns=['v0', 'v1', 'v2'])\n",
    "\n",
    "    # Convert to dask\n",
    "    verts_ddf = dd.from_pandas(verts_df, npartitions=n_workers)\n",
    "    tris_ddf = dd.from_pandas(tris_df, npartitions=n_workers)\n",
    "\n",
    "    # Declare HoloViews element\n",
    "    tri_nodes = hv.Nodes(verts_ddf, ['x', 'y', 'index'], ['z'])\n",
    "    trimesh = hv.TriMesh((tris_ddf, tri_nodes))\n",
    "    return(trimesh)\n",
    "\n",
    "# Triangulate MPAS primary mesh:\n",
    "# Triangulate each polygon in a heterogenous mesh of n-gons by connecting\n",
    "# each internal polygon vertex to the first vertex. Uses the MPAS\n",
    "# auxilliary variables verticesOnCell, and nEdgesOnCell.\n",
    "# The function is decorated with Numba's just-in-time compiler so that it is translated into\n",
    "# optimized machine code for better peformance\n",
    "\n",
    "@jit(nopython=True)\n",
    "def triangulatePoly(verticesOnCell, nEdgesOnCell):\n",
    "\n",
    "    # Calculate the number of triangles. nEdgesOnCell gives the number of vertices for each \n",
    "    # cell (polygon)\n",
    "    # The number of triangles per polygon is the number of vertices minus 2.\n",
    "    \n",
    "    nTriangles = np.sum(nEdgesOnCell - 2)\n",
    "\n",
    "    triangles = np.ones((nTriangles, 3), dtype=np.int64)\n",
    "    nCells = verticesOnCell.shape[0]\n",
    "    triIndex = 0\n",
    "    for j in range(nCells):\n",
    "        for i in range(nEdgesOnCell[j]-2):\n",
    "            triangles[triIndex][0] = verticesOnCell[j][0]\n",
    "            triangles[triIndex][1] = verticesOnCell[j][i+1]\n",
    "            triangles[triIndex][2] = verticesOnCell[j][i+2]\n",
    "            triIndex += 1\n",
    "\n",
    "    return triangles\n",
    "\n",
    "def set_up_mesh(mesh_ds, n_workers=1):\n",
    "    # Fetch lat and lon coordinates for the primal and dual mesh.\n",
    "    lonCell = mesh_ds['lonCell'].values * 180.0 / math.pi\n",
    "    latCell = mesh_ds['latCell'].values * 180.0 / math.pi\n",
    "    lonCell = ((lonCell - 180.0) % 360.0) - 180.0\n",
    "\n",
    "    lonVertex = mesh_ds['lonVertex'].values * 180.0 / math.pi\n",
    "    latVertex = mesh_ds['latVertex'].values * 180.0 / math.pi\n",
    "    lonVertex = ((lonVertex - 180.0) % 360.0) - 180.0\n",
    "\n",
    "    # Get triangle indices for each vertex in the MPAS file. Note, indexing in MPAS starts from 1, not zero :-(\n",
    "    tris = mesh_ds.cellsOnVertex.values - 1\n",
    "\n",
    "    # Guarantees consistent clockwise winding order (required by Datashade and Matplotlib)\n",
    "    tris = orderCCW(lonCell,latCell,tris)\n",
    "\n",
    "    # Unzip the mesh along a constant line of longitude for PCS coordinates (central_longitude=0.0)\n",
    "    central_longitude = 0.0\n",
    "    projection = ccrs.Robinson(central_longitude=central_longitude)\n",
    "    tris = unzipMesh(lonCell,tris,90.0)\n",
    "\n",
    "    # Project verts from geographic to PCS coordinates\n",
    "    xPCS, yPCS, _ = projection.transform_points(ccrs.PlateCarree(), lonCell, latCell).T\n",
    "    \n",
    "    return xPCS, yPCS, tris, n_workers, projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d158a-4c11-48ac-bcce-61bc5aa64da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datashader_wrapper(mesh_ds, unstructured_ds, primalVarName, time, level=None, \n",
    "                       pixel_height=400, pixel_width=400, pixel_ratio=1, x_sampling=None, \n",
    "                       y_sampling=None, lon_range=None, lat_range=None):\n",
    "    \n",
    "    # Selects target variable from dataset based on timestep (suppresses error if no time dimension)\n",
    "    try:\n",
    "        primalVar = unstructured_ds[primalVarName].isel(time=time).values\n",
    "    except ValueError:\n",
    "        primalVar = unstructured_ds[primalVarName].values\n",
    "    \n",
    "    if np.ndim(primalVar) > 1 and level==None:\n",
    "        raise ValueError('Select a level to knock this down to a 1D array.')\n",
    "    elif np.ndim(primalVar) > 1 and level != None:\n",
    "        primalVar = unstructured_ds[primalVarName].sel(lev=level, method='nearest').isel(time=time).values\n",
    "    \n",
    "    xPCS, yPCS, tris, n_workers, projection = set_up_mesh(mesh_ds)\n",
    "    # Possibly use xPCS, yPCS and tris to calc vorticity and other derived functions\n",
    "    \n",
    "    trimesh = createHVTriMesh(xPCS,yPCS,tris, primalVar,n_workers=n_workers)\n",
    "    \n",
    "    if lon_range != None and lat_range != None:\n",
    "        x_range, y_range, _ = projection.transform_points(ccrs.PlateCarree(), np.array(lon_range), np.array(lat_range)).T\n",
    "        x_range = tuple(x_range)\n",
    "        y_range = tuple(y_range)\n",
    "    else:\n",
    "        x_range = None\n",
    "        y_range = None\n",
    "    \n",
    "    # Use precompute so it caches the data internally\n",
    "    rasterized = hds_rasterize(trimesh, aggregator='mean', precompute=True, height=pixel_height, \n",
    "                               width=pixel_width, pixel_ratio=pixel_ratio, x_sampling=x_sampling, \n",
    "                               y_sampling=y_sampling, x_range=x_range, y_range=y_range)\n",
    "    \n",
    "    return rasterized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b908883-4b02-461d-b417-b8accb71675b",
   "metadata": {},
   "source": [
    "# Florence MPAS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77610cee-f8c1-4e29-90f3-bf692b57bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "florence_folders = r\"/storage/home/cmz5202/group/cnd5285/MPAS_betacast_sample/\"\n",
    "lores_mesh_file = os.path.join(florence_folders, 'FHIST-mpasa120-betacast-ERA5-x001_INIC.nc')\n",
    "lores_files = choose_forecast(florence_folders, regridded=False, init_time='0Z')\n",
    "h1_ds = lores_files[0]\n",
    "h2_ds = lores_files[1]\n",
    "h4_ds = lores_files[2]\n",
    "\n",
    "lores_mesh = xr.open_dataset(lores_mesh_file, decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b653d7-c35a-4557-aa6d-ccb6f1f6f68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8439d1-0e3d-4212-b0b4-877a4ded4ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lores_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ca452-6ea0-401e-9b91-23d6e8ef0190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 1: calculaute horizontal vorticity using Davies-Jones 1992\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ca31d-1ef9-4227-a6da-ab8f9706e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_ds['maxU10'] = h1_ds['U10'].max(dim='time')\n",
    "h1_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3454981-52e4-486c-bcb7-1ea99f3a5074",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_ds['U10'].max(dim='time').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02382d79-0209-425c-ad6a-385230b935c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_ds['maxU10'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15dd15a-7688-4268-9e15-b76165ce74ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cedecac-a3a6-4507-b9e9-2d6f4ec199fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lores_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b3fdc9-3728-43ed-b29e-10c08eb5878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h2_ds['FLUT'].values.min())\n",
    "print(h2_ds['FLUT'].values.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911cf7a4-5aa8-43c9-82e3-ce31333263eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block to create wind swath colormap\n",
    "\n",
    "# < 18 m/s is discarded (< TS strength)\n",
    "# Maybe do TS strength in 10's in shades of blue/purple?\n",
    "\n",
    "# 33-? (>70) m/s Allen was strongest ever at 190 mph (85 m/s)\n",
    "# Puts range at 0-85, maybe have 0-18 = white?\n",
    "\n",
    "colors = [(0, '#FFFFFF'), # white\n",
    "          ((17/85), '#FFFFFF'),\n",
    "          ((18/85), '#FFA500'), # tropical storm strength winds\n",
    "          ((32/85), '#FFA500'),\n",
    "          ((33/85), '#880808'), # hurricane strength winds\n",
    "          (1, '#880808')\n",
    "         ]\n",
    "\n",
    "# omit white, just start at TS strength\n",
    "#colors2 = [(0, '#FFA500'), ((14/67), '#FFA500'), ((15/67), '#880808'), (1, '#880808')]\n",
    "\n",
    "ws_cmp = LinearSegmentedColormap.from_list('wind swaths', colors, N=85)\n",
    "#ws_cmp = LinearSegmentedColormap.from_list('wind swaths', colors2, N=68)\n",
    "\n",
    "ws_cmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625d7fd-d388-40cb-ac52-2d992d1cefc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "central_longitude = 0.0\n",
    "projection = ccrs.Robinson(central_longitude=central_longitude)\n",
    "\n",
    "target_var = 'maxU10'\n",
    "target_time = 2\n",
    "pixel_ratio = 5\n",
    "lon_range, lat_range = find_TC_bbox(h1_ds, 'north atlantic', target_time, center_dist=1000)\n",
    "clipped_h1ds = h1_ds\n",
    "rasterized_lowres = datashader_wrapper(lores_mesh, h1_ds, target_var, target_time, \n",
    "                                       lon_range=lon_range, lat_range=lat_range, pixel_ratio=pixel_ratio)\n",
    "rasterized_lowres.opts(tools=['hover'], colorbar=True, cmap=ws_cmp, clim=(0, 85)) * gf.coastline(projection=projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28caab3d-0dc5-47ed-92f7-c09f1a5cdd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hv.output(width=400, height=400)\n",
    "\n",
    "central_longitude = 0.0\n",
    "projection = ccrs.Robinson(central_longitude=central_longitude)\n",
    "\n",
    "target_var = 'U10'\n",
    "target_time = 2\n",
    "pixel_ratio = 5\n",
    "lon_range, lat_range = find_TC_bbox(h1_ds, 'north atlantic', target_time, center_dist=1000)\n",
    "rl1 = datashader_wrapper(lores_mesh, h1_ds, target_var, 1, \n",
    "                                       lon_range=lon_range, lat_range=lat_range, pixel_ratio=pixel_ratio)\n",
    "rl2 = datashader_wrapper(lores_mesh, h1_ds, target_var, 2, \n",
    "                                       lon_range=lon_range, lat_range=lat_range, pixel_ratio=pixel_ratio)\n",
    "rl3 = datashader_wrapper(lores_mesh, h1_ds, target_var, 3, \n",
    "                                       lon_range=lon_range, lat_range=lat_range, pixel_ratio=pixel_ratio)\n",
    "rl4 = datashader_wrapper(lores_mesh, h1_ds, target_var, 4, \n",
    "                                       lon_range=lon_range, lat_range=lat_range, pixel_ratio=pixel_ratio)\n",
    "rl5 = datashader_wrapper(lores_mesh, h1_ds, target_var, 5, \n",
    "                                       lon_range=lon_range, lat_range=lat_range, pixel_ratio=pixel_ratio)\n",
    "\n",
    "layout = rl1.opts(colorbar=True, cmap=ws_cmp, clim=(0, 20)) * rl2.opts(colorbar=True, cmap=ws_cmp, clim=(0, 20)) *\\\n",
    "        rl3.opts(colorbar=True, cmap=ws_cmp, clim=(0, 20)) * rl4.opts(colorbar=True, cmap=ws_cmp, clim=(0, 20)) *\\\n",
    "        rl5.opts(colorbar=True, cmap=ws_cmp, clim=(0, 20)) \n",
    "layout.opts(tools=['hover'], framewise=True) * gf.coastline(projection=projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b231ab-6b8e-48c2-a6f0-449c05317956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hv.output(width=400, height=400)\n",
    "\n",
    "central_longitude = 0.0\n",
    "projection = ccrs.Robinson(central_longitude=central_longitude)\n",
    "\n",
    "target_var = 'PSL'\n",
    "target_time = 2\n",
    "pixel_ratio = 5\n",
    "lon_range, lat_range = find_TC_bbox(h1_ds, 'north atlantic', target_time, center_dist=1000)\n",
    "rasterized_lowres1 = datashader_wrapper(lores_mesh, h1_ds, target_var, target_time, \n",
    "                                       lon_range=lon_range, lat_range=lat_range, pixel_ratio=pixel_ratio)\n",
    "rasterized_lowres2 = datashader_wrapper(lores_mesh, h1_ds, target_var, 3, \n",
    "                                       lon_range=lon_range, lat_range=lat_range, pixel_ratio=pixel_ratio)\n",
    "layout = rasterized_lowres1.opts(colorbar=True, cmap='RdBu') * rasterized_lowres2.opts(colorbar=True, cmap='RdBu')\n",
    "layout.opts(tools=['hover'], framewise=False) * gf.coastline(projection=projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f7fdc7-08bf-4c47-94d5-093c8891417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hds_rasterize(hv.Image(h1_ds.U10.isel(time=[2]))).opts(cmap='jet', colorbar=True, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf7e40-ffae-4ad6-8537-1b1df9957e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datashader]",
   "language": "python",
   "name": "conda-env-datashader-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
